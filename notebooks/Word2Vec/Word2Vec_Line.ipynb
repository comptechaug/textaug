{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec augmentations line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузить данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.read_csv('../../data/twitts/positive.csv', sep=';', header=None).assign(positive=1)\n",
    "df_neg = pd.read_csv('../../data/twitts/negative.csv', sep=';', header=None).assign(positive=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df_pos[[3,'positive']].append( df_neg[[3,'positive']], ignore_index=True ).rename({3:'tweet'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ну любишь или нет? — Я не знаю кто ты бля:D ht...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @SpoonLamer: Ох,900 :D ну это конечно же @t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @veregijytaqo: У тебя есть ухажёр? Нет - мо...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Поприветствуем моего нового читателя @Alexey17...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Теперь у меня есть частичка Сиднея :) #Sydney ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Люблю маму и папу!!!!а в остальное я так...-вл...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @dicyziqecida: Как-то я забыла, что вчера п...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@MrsRourke_s_tit @_vivante @dyu_bryun так было...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@Kruglova_Julia_  дааааа))\\nТы... Ты... Ты и т...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@Alex_Shvarz :)) О, нет. Вы ведь всё равно обз...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  positive\n",
       "0   @first_timee хоть я и школота, но поверь, у на...         1\n",
       "1   Да, все-таки он немного похож на него. Но мой ...         1\n",
       "2   RT @KatiaCheh: Ну ты идиотка) я испугалась за ...         1\n",
       "3   RT @digger2912: \"Кто то в углу сидит и погибае...         1\n",
       "4   @irina_dyshkant Вот что значит страшилка :D\\nН...         1\n",
       "5   ну любишь или нет? — Я не знаю кто ты бля:D ht...         1\n",
       "6   RT @SpoonLamer: Ох,900 :D ну это конечно же @t...         1\n",
       "7   RT @veregijytaqo: У тебя есть ухажёр? Нет - мо...         1\n",
       "8   Поприветствуем моего нового читателя @Alexey17...         1\n",
       "9   Теперь у меня есть частичка Сиднея :) #Sydney ...         1\n",
       "10  Люблю маму и папу!!!!а в остальное я так...-вл...         1\n",
       "11  RT @dicyziqecida: Как-то я забыла, что вчера п...         1\n",
       "12  @MrsRourke_s_tit @_vivante @dyu_bryun так было...         1\n",
       "13  @Kruglova_Julia_  дааааа))\\nТы... Ты... Ты и т...         1\n",
       "14  @Alex_Shvarz :)) О, нет. Вы ведь всё равно обз...         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop_duplicates() #важно, потому что дубликаты кажется есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    110396\n",
       "0    107044\n",
       "Name: positive, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.positive.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убрать из данных характерные для твиттера вещи (RT, @ и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.tweet = tweets['tweet'].apply(lambda x: re.sub('[\\Wa-zA-Z_\\d]+', ' ', x) )\n",
    "tweets.tweet = tweets['tweet'].apply(lambda x: x.lower().strip() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного пристальнее посмотреть на записи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 а стояк теперь снова стояк вселенная вернула все на свои места\n",
      "2 прифетигг солныско каг тфаи дила мну сичас фф больниську идеть к логопеду\n",
      "3 да нашла фоточку в иг и нагло спиздила ничего с фотографиями меня уже статусы в вконтакте бывают\n",
      "4 а у нас в нижнем слякотная погода брр но у нас офигенный привоз заходим заходим\n",
      "5 короче видимо ни в какой архитектурный я не иду там капец конечно\n",
      "6 ну в сделаешь тогда я дарья а ты\n",
      "7 плак плак надеюсь на драфте тогда их вытяну\n",
      "8 а моя кроме поорать еще просится на балкон хвост поморозить минуту посидит и назад просится\n",
      "9 каждому так болеть когда к тебе друзья в гости ходят\n",
      "10 мам мне так хреново выпей таблетку и на работу на следующей недели пойдем в сауну мама умеет поддержать и добавить стимула\n"
     ]
    }
   ],
   "source": [
    "for i, v in zip(range(1,100), tweets['tweet'][50:60]):\n",
    "    print(i, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прелестно.\n",
    "Пора переводить данные, но сначала разделю на train и test части, чтоб аугментировать только train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets.tweet\n",
    "y = tweets.positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163080,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W2V augmentation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачать файл с векторами [отсюда](http://panchenko.me/data/dsl-backup/w2v-ru/all.norm-sz100-w10-cb0-it1-min100.w2v)\n",
    "\n",
    "Я использую самый лёгкий файл, но в перспективе можно и более тяжёлые, всё лежит [здесь](https://nlpub.mipt.ru/Russian_Distributional_Thesaurus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mipt_model = gensim.models.KeyedVectors.load_word2vec_format('mipt_vecs.w2v', binary=True, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишу тупенькую функцию, чтоб аугментировать предложения, но сначала ещё кое-что"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w2v = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mipt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikitap/programs/anaconda3/lib/python3.7/site-packages/gensim/similarities/index.py:184: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n",
      "  index = AnnoyIndex(num_features)\n"
     ]
    }
   ],
   "source": [
    "from gensim.similarities.index import AnnoyIndexer #вопрос, может ли работать\n",
    "annoy_index = AnnoyIndexer(mipt_model, num_trees=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартный поиск наиболее похожего слова слишком долгий, поэтому буду пользоваться [`AnnoyIndexer`](https://radimrehurek.com/gensim/auto_examples/tutorials/run_annoy.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неисследованная опция `num_trees` кажется улучшает качество поиска похожего слова; если компьютер мощный, то можно попробовать поднять значение до `100-500`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 µs ± 50.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "89.1 ms ± 1.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model.most_similar('слово', topn=2, indexer=annoy_index)\n",
    "%timeit model.most_similar('слово', topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annoy: [('слово', 1.0), ('произнесено', 0.6672296822071075)]\n",
      "Standard: [('слово…', 0.8392893671989441), ('словечко', 0.794983983039856)]\n"
     ]
    }
   ],
   "source": [
    "print( 'Annoy:', model.most_similar('слово', topn=2, indexer=annoy_index) )\n",
    "print( 'Standard:', model.most_similar('слово', topn=2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sen_aug_one_change(sen):\n",
    "    words = sen.split(' ')\n",
    "    indexes = list( range(len(words)) )\n",
    "    random.shuffle(indexes)\n",
    "    new_words = list()\n",
    "    for i in indexes:\n",
    "        if words[i] in model:\n",
    "            words[i] = model.most_similar(words[i], topn=1)[0][0]\n",
    "            return ' '.join(words)\n",
    "    return sen  # no replacement was possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sen_aug_one_change_annoy(sen):\n",
    "    words = sen.split(' ')\n",
    "    indexes = list( range(len(words)) )\n",
    "    random.shuffle(indexes)\n",
    "    new_words = list()\n",
    "    for i in indexes:\n",
    "        if words[i] in model:\n",
    "            words[i] = model.most_similar(words[i], topn=2, indexer=annoy_index)[1][0]\n",
    "            return ' '.join(words)\n",
    "    return sen  # no replacement was possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sen_aug_all_changes(sen):\n",
    "    words = sen.split(' ')\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in model:\n",
    "            words[i] = model.most_similar(words[i], topn=3)[1][0]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sen_aug_all_changes_annoy(sen):\n",
    "    words = sen.split(' ')\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in model:\n",
    "            words[i] = model.most_similar(words[i], topn=3, indexer=annoy_index)[1][0]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример полностью переделанных твитов, но для быстроты будем менять по одному слову"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tweet: я же знала что скучал но сомневалась\n",
      "All change words: мне так догадывалась не тосковал не знала\n",
      "All change words (with annoy): меня всетаки понимала действительно скорпиусом ли надеялась\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(tweets))\n",
    "print('Original tweet:', tweets.tweet[i])\n",
    "print('All change words:', sen_aug_all_changes(tweets.tweet[i]) )\n",
    "print('All change words (with annoy):', sen_aug_all_changes_annoy(tweets.tweet[i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравниваю функции по скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45 s ± 33.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "4.12 ms ± 151 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "89.5 ms ± 3.79 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "372 µs ± 4.68 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sen_aug_all_changes(X_w2v[0])\n",
    "%timeit sen_aug_all_changes_annoy(X_w2v[0])\n",
    "%timeit sen_aug_one_change(X_w2v[0])\n",
    "%timeit sen_aug_one_change_annoy(X_w2v[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С учётом количества данных в `X_w2v` = 163080, предпочитаю скорость качеству"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 s, sys: 5.41 s, total: 58.2 s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%time X_add = X_w2v.apply(lambda x: sen_aug_one_change_annoy(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры того, какие аугментации получились"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin: тогда это не гарантийный случай\n",
      "Aug: чеперухи это не гарантийный случай\n",
      "__________\n",
      "Origin: сьогодні реал випадково не грає а то знов все пропущу\n",
      "Aug: сьогодні реал випадково не вигуки а то знов все пропущу\n",
      "__________\n",
      "Origin: знаю ожидания уже не в азарт а в безумство\n",
      "Aug: знаю ожидания апреля] не в азарт а в безумство\n",
      "__________\n",
      "Origin: лол просил сигну для себя кефир сделал для я лох\n",
      "Aug: лол отозвал сигну для себя кефир сделал для я лох\n",
      "__________\n",
      "Origin: удачи слюнявый который мне никогда бля не отвечает но похуй удачи\n",
      "Aug: удачи слюнявый который мне венхауге бля не отвечает но похуй удачи\n",
      "__________\n",
      "Origin: чикаго против анахайма очень хочется посмотреть\n",
      "Aug: чикаго против анахайма всегда хочется посмотреть\n",
      "__________\n",
      "Origin: почему в контакте в семейном положение нельзя написать в пассивном поиске типа хочется но лень\n",
      "Aug: почему в контакте в семейном положение нельзя написать в активном поиске типа хочется но лень\n",
      "__________\n",
      "Origin: интернет не делает твой мир ярче\n",
      "Aug: сайты не делает твой мир ярче\n",
      "__________\n",
      "Origin: новогоднее настроение\n",
      "Aug: новогодним настроение\n",
      "__________\n",
      "Origin: посвящение я вас люблю\n",
      "Aug: ученичество я вас люблю\n",
      "__________\n",
      "Origin: на улице прекрасная погода а я дома сижу\n",
      "Aug: трехклассной улице прекрасная погода а я дома сижу\n",
      "__________\n",
      "Origin: получите эстетическое удовольствие\n",
      "Aug: получите эстетическое удовольствия\n",
      "__________\n",
      "Origin: не успели подать сегодня заявления на визу не хватило каких то минут а так вчера все хорошо распланировал но неож\n",
      "Aug: не успели дать сегодня заявления на визу не хватило каких то минут а так вчера все хорошо распланировал но неож\n",
      "__________\n",
      "Origin: интересно было бы это стильно живи вы в выхино\n",
      "Aug: интересно было бы запутали, — стильно живи вы в выхино\n",
      "__________\n",
      "Origin: по инглишу задали составить текст про человека которым восхищаешься\n",
      "Aug: по инглишу задали составить текст про осознающего которым восхищаешься\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "n_tweets = 15\n",
    "ind = random.randint(n_tweets, len(X_w2v))\n",
    "for w2v,add in zip(X_w2v.values[ind-15:ind], X_add.values[ind-n_tweets:ind]):\n",
    "    print('Origin:', w2v)\n",
    "    print('Aug:', add )\n",
    "    print('__________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_w2v.append( X_add, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.append(y_train, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326160 326160\n"
     ]
    }
   ],
   "source": [
    "print( X_train.shape[0], y_train.shape[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова нужно вычистить дупликаты, сделаю это немного странно, т.к. нужно деражать правильные ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'tweet': X_train.apply(lambda x: re.sub('(\\W+|\\d+|[A-Za-z]+|_+)', ' ', x) ), \n",
    "                         'positive': y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>съехал с рельс и теперь заправляется кофе</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>так ведь никто не заставляет вляпываться то те...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>к любви отношусь со смехом</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>интересно а мой брат в лет будет приезжать ко ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>бля мне этот сон не дает покоя он был таким ре...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326155</th>\n",
       "      <td>сибирь красноярск середина декабря завтрашний ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326156</th>\n",
       "      <td>окей я на электронную почту тебе сейчас скину ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326157</th>\n",
       "      <td>гиляз ты же говорила что типо забила на это во...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326158</th>\n",
       "      <td>зыонг года интенс любимая в пролёте</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326159</th>\n",
       "      <td>я не знаю что со мной но мне так охото побегат...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  positive\n",
       "0               съехал с рельс и теперь заправляется кофе         0\n",
       "1       так ведь никто не заставляет вляпываться то те...         0\n",
       "2                              к любви отношусь со смехом         1\n",
       "3       интересно а мой брат в лет будет приезжать ко ...         1\n",
       "4       бля мне этот сон не дает покоя он был таким ре...         0\n",
       "...                                                   ...       ...\n",
       "326155  сибирь красноярск середина декабря завтрашний ...         0\n",
       "326156  окей я на электронную почту тебе сейчас скину ...         1\n",
       "326157  гиляз ты же говорила что типо забила на это во...         0\n",
       "326158                зыонг года интенс любимая в пролёте         0\n",
       "326159  я не знаю что со мной но мне так охото побегат...         0\n",
       "\n",
       "[326160 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318234"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.tweet, df_train.positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай можно ещё раз почистить, ещё раз убрать все знаки препинания и цифры\n",
    "\n",
    "Но для начала нужно слить train и test, чтоб vectorize все строки, поэтому запоминаю `split_index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = X_train.shape[0]\n",
    "X = X_train.append(X_test).apply(lambda x: re.sub('(\\W+|\\d+|[A-Za-z]+|_+)', ' ', x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326150         бедняга зохра издвается парившим ним наверно\n",
       "326151    нет тортиков принципе мамины рафаэлки и армянс...\n",
       "326152    ты про случай в туалете ну мы просто случайно ...\n",
       "326153                    полина подумать придёт бедапечаль\n",
       "326154    написать что ли пост о войне с хаскеля на риве...\n",
       "326155    сибирь красноярск середина декабря завтрашний ...\n",
       "326156    окей я на электронную почту тебе сейчас скину ...\n",
       "326157    гиляз ты же говорила что типо забила на это во...\n",
       "326158                  зыонг года интенс любимая в пролёте\n",
       "326159    я не знаю что со мной но мне так охото побегат...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[split_index-10:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_test) + len(X_train) == len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372594"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почищено, теперь векторизую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vect = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова разделяю по split индексу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vect_train, X_vect_test = X_vect[:split_index,], X_vect[split_index:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры верны: True\n",
      "Размеры верны: True\n"
     ]
    }
   ],
   "source": [
    "print('Размеры верны:', X_vect_train.shape[0] == y_train.shape[0] )\n",
    "print('Размеры верны:', X_vect_test.shape[0] == y_test.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['автоматов',\n",
       " 'автоматом',\n",
       " 'автоматттттт',\n",
       " 'автоматты',\n",
       " 'автоматчик',\n",
       " 'автоматы',\n",
       " 'автомеханика',\n",
       " 'автомеханический',\n",
       " 'автомобиле',\n",
       " 'автомобилей',\n",
       " 'автомобилем',\n",
       " 'автомобили',\n",
       " 'автомобилист',\n",
       " 'автомобилистов',\n",
       " 'автомобилисты',\n",
       " 'автомобиль',\n",
       " 'автомобильная',\n",
       " 'автомобильное',\n",
       " 'автомобильной',\n",
       " 'автомобильном']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[800:820]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go учиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_vect_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_vect_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54360,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7336460632818249"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7446339441612727"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ок, хорошо\n",
    "\n",
    "теперь можно менять параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf, {'C': [1.25, 1.35]}, cv=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=400, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None, param_grid={'C': [1.25, 1.35]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_vect_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.35}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_vect_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7328550404709345"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7430825843889322"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
